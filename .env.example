# Firecrawl Scraper v2.0 Configuration
# Get your API key from: https://www.firecrawl.dev/

# ========== Required ==========
FIRECRAWL_API_KEY=your_api_key_here

# ========== API Configuration ==========
# API version (v2 is default with new features)
FIRECRAWL_API_VERSION=v2

# Backup API key (optional)
FIRECRAWL_BACKUP_KEY=optional_backup_key_here

# ========== Proxy Configuration ==========
# Options: auto, basic, stealth
FIRECRAWL_PROXY_TYPE=auto

# Proxy Locations (comma-separated country codes)
FIRECRAWL_LOCATIONS=US,DE,GB,AU,FR

# ========== Retry Configuration ==========
FIRECRAWL_MAX_RETRIES=3
FIRECRAWL_RETRY_DELAY=2000

# ========== Output Configuration ==========
FIRECRAWL_OUTPUT_DIR=./data

# ========== Logging ==========
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ========== NEW v2.0: Batch Scraping ==========
# Maximum URLs per batch request (max 10000)
MAX_BATCH_SIZE=1000

# Polling interval for batch status (seconds)
BATCH_POLL_INTERVAL=5

# Maximum concurrent requests in batch
BATCH_MAX_CONCURRENT=100

# ========== NEW v2.0: Actions Configuration ==========
# Default wait timeout for actions (milliseconds)
DEFAULT_WAIT_TIMEOUT=30000

# Default scroll amount (pixels)
DEFAULT_SCROLL_AMOUNT=1000

# Enable screenshots by default
ENABLE_SCREENSHOTS=false

# Enable mobile emulation by default
ENABLE_MOBILE_EMULATION=false

# ========== NEW v2.0: Change Tracking ==========
# Enable change tracking feature
CHANGE_TRACKING_ENABLED=false

# Check interval for tracked URLs (seconds, default 24h)
CHANGE_TRACKING_INTERVAL=86400

# Webhook URL for change notifications (optional)
CHANGE_TRACKING_WEBHOOK=

# Email for change notifications (optional)
CHANGE_TRACKING_NOTIFY_EMAIL=

# ========== NEW v2.0: WebSocket Configuration ==========
# Enable WebSocket for real-time monitoring
WEBSOCKET_ENABLED=true

# Reconnection attempts on disconnect
WEBSOCKET_RECONNECT_ATTEMPTS=3

# Ping interval to keep connection alive (seconds)
WEBSOCKET_PING_INTERVAL=30

# ========== NEW v2.0: Media Extraction ==========
# Enable media extraction features
MEDIA_EXTRACTION_ENABLED=false

# Enable PDF parsing
PDF_EXTRACTION_ENABLED=false

# Enable DOCX parsing
DOCX_EXTRACTION_ENABLED=false

# Enable image OCR
IMAGE_OCR_ENABLED=false

# Maximum media file size (MB)
MAX_MEDIA_SIZE_MB=50

# ========== LLM Extraction ==========
# Model for LLM-powered extraction
LLM_EXTRACTION_MODEL=gpt-4o-mini

# Maximum tokens for extraction
LLM_MAX_TOKENS=4096

# ========== Quality Thresholds ==========
# Minimum content length for valid pages (characters)
MIN_CONTENT_LENGTH=1000

# Duplicate detection threshold (0.0-1.0)
DUPLICATE_THRESHOLD=0.95

# ========== Performance ==========
# Maximum concurrent requests
MAX_CONCURRENT_REQUESTS=5

# Request timeout (seconds)
REQUEST_TIMEOUT=60

# ========== Default Scraping Options ==========
# Default strategy: crawl, map, extract, batch, dynamic
DEFAULT_STRATEGY=map

# Default max pages per source
DEFAULT_MAX_PAGES=50

# Enable stealth mode by default
DEFAULT_USE_STEALTH=false
